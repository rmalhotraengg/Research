{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3bed0962-574b-4fb2-8063-15f3d71d33a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DescribeResult(nobs=8192000, minmax=(array([-80.]), array([0.])), mean=array([-36.32202353]), variance=array([173.18573026]), skewness=array([-0.62897657]), kurtosis=array([1.16821915]))\n",
      "DescribeResult(nobs=8192000, minmax=(array([-63.09787973]), array([77.94489739])), mean=array([0.36134002]), variance=array([96.05843834]), skewness=array([0.62643615]), kurtosis=array([2.30614789]))\n",
      "(500, 128, 128)\n",
      "(500, 128, 128)\n",
      "DescribeResult(nobs=8192000, minmax=(array([-0.68]), array([0.92])), mean=array([0.19355953]), variance=array([0.06927429]), skewness=array([-0.62897657]), kurtosis=array([1.16821915]))\n",
      "DescribeResult(nobs=8192000, minmax=(array([-0.84265707]), array([0.8773768])), mean=array([-0.06876415]), variance=array([0.01428591]), skewness=array([0.62643615]), kurtosis=array([2.30614789]))\n",
      "Epoch 1/20\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1093 - mae: 0.2860\n",
      "Epoch 1: val_loss improved from inf to 0.02878, saving model to ./weights\\model_ResNet.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Raveesh\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 468s 8s/step - loss: 0.1093 - mae: 0.2860 - val_loss: 0.0288 - val_mae: 0.1194\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0341 - mae: 0.1594\n",
      "Epoch 2: val_loss did not improve from 0.02878\n",
      "45/45 [==============================] - 403s 9s/step - loss: 0.0341 - mae: 0.1594 - val_loss: 0.8299 - val_mae: 0.7917\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0246 - mae: 0.1340\n",
      "Epoch 3: val_loss did not improve from 0.02878\n",
      "45/45 [==============================] - 386s 9s/step - loss: 0.0246 - mae: 0.1340 - val_loss: 0.7118 - val_mae: 0.6924\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0216 - mae: 0.1243\n",
      "Epoch 4: val_loss did not improve from 0.02878\n",
      "45/45 [==============================] - 384s 9s/step - loss: 0.0216 - mae: 0.1243 - val_loss: 0.2462 - val_mae: 0.3023\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0206 - mae: 0.1209\n",
      "Epoch 5: val_loss did not improve from 0.02878\n",
      "45/45 [==============================] - 394s 9s/step - loss: 0.0206 - mae: 0.1209 - val_loss: 1.0732 - val_mae: 0.9972\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0197 - mae: 0.1175  \n",
      "Epoch 6: val_loss improved from 0.02878 to 0.01874, saving model to ./weights\\model_ResNet.h5\n",
      "45/45 [==============================] - 4833s 110s/step - loss: 0.0197 - mae: 0.1175 - val_loss: 0.0187 - val_mae: 0.1109\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0191 - mae: 0.1152\n",
      "Epoch 7: val_loss did not improve from 0.01874\n",
      "45/45 [==============================] - 370s 8s/step - loss: 0.0191 - mae: 0.1152 - val_loss: 0.0219 - val_mae: 0.1139\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0186 - mae: 0.1132\n",
      "Epoch 8: val_loss did not improve from 0.01874\n",
      "45/45 [==============================] - 364s 8s/step - loss: 0.0186 - mae: 0.1132 - val_loss: 0.0192 - val_mae: 0.1114\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0184 - mae: 0.1122\n",
      "Epoch 9: val_loss did not improve from 0.01874\n",
      "45/45 [==============================] - 366s 8s/step - loss: 0.0184 - mae: 0.1122 - val_loss: 0.0204 - val_mae: 0.1131\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0182 - mae: 0.1114\n",
      "Epoch 10: val_loss did not improve from 0.01874\n",
      "45/45 [==============================] - 359s 8s/step - loss: 0.0182 - mae: 0.1114 - val_loss: 0.0199 - val_mae: 0.1127\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0180 - mae: 0.1108\n",
      "Epoch 11: val_loss did not improve from 0.01874\n",
      "45/45 [==============================] - 368s 8s/step - loss: 0.0180 - mae: 0.1108 - val_loss: 0.0204 - val_mae: 0.1131\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0179 - mae: 0.1101\n",
      "Epoch 12: val_loss did not improve from 0.01874\n",
      "45/45 [==============================] - 395s 9s/step - loss: 0.0179 - mae: 0.1101 - val_loss: 0.0199 - val_mae: 0.1125\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0178 - mae: 0.1097\n",
      "Epoch 13: val_loss did not improve from 0.01874\n",
      "45/45 [==============================] - 381s 8s/step - loss: 0.0178 - mae: 0.1097 - val_loss: 0.0230 - val_mae: 0.1158\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0177 - mae: 0.1092\n",
      "Epoch 14: val_loss did not improve from 0.01874\n",
      "45/45 [==============================] - 382s 8s/step - loss: 0.0177 - mae: 0.1092 - val_loss: 0.0198 - val_mae: 0.1122\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0176 - mae: 0.1089\n",
      "Epoch 15: val_loss did not improve from 0.01874\n",
      "45/45 [==============================] - 308s 7s/step - loss: 0.0176 - mae: 0.1089 - val_loss: 0.0257 - val_mae: 0.1180\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0174 - mae: 0.1083\n",
      "Epoch 16: val_loss did not improve from 0.01874\n",
      "45/45 [==============================] - 250s 6s/step - loss: 0.0174 - mae: 0.1083 - val_loss: 0.0188 - val_mae: 0.1111\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0174 - mae: 0.1083\n",
      "Epoch 17: val_loss did not improve from 0.01874\n",
      "45/45 [==============================] - 242s 5s/step - loss: 0.0174 - mae: 0.1083 - val_loss: 0.0187 - val_mae: 0.1109\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0173 - mae: 0.1079\n",
      "Epoch 18: val_loss did not improve from 0.01874\n",
      "45/45 [==============================] - 240s 5s/step - loss: 0.0173 - mae: 0.1079 - val_loss: 0.0187 - val_mae: 0.1109\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0174 - mae: 0.1079\n",
      "Epoch 19: val_loss did not improve from 0.01874\n",
      "45/45 [==============================] - 250s 6s/step - loss: 0.0174 - mae: 0.1079 - val_loss: 0.0187 - val_mae: 0.1109\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0173 - mae: 0.1078\n",
      "Epoch 20: val_loss did not improve from 0.01874\n",
      "45/45 [==============================] - 243s 5s/step - loss: 0.0173 - mae: 0.1078 - val_loss: 0.0191 - val_mae: 0.1116\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model_json' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 123\u001b[0m\n\u001b[0;32m    120\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m    122\u001b[0m \u001b[38;5;66;03m# Call the training function\u001b[39;00m\n\u001b[1;32m--> 123\u001b[0m \u001b[43mtraining_2\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mspectogram/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./weights\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[5], line 108\u001b[0m, in \u001b[0;36mtraining_2\u001b[1;34m(path_save_spectrogram, weights_path, epochs, batch_size)\u001b[0m\n\u001b[0;32m     99\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m    100\u001b[0m     x\u001b[38;5;241m=\u001b[39mx_train,\n\u001b[0;32m    101\u001b[0m     y\u001b[38;5;241m=\u001b[39my_train,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    105\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[checkpoint]\n\u001b[0;32m    106\u001b[0m    )\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(weights_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_ResNet.json\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m json_file:\n\u001b[1;32m--> 108\u001b[0m     json_file\u001b[38;5;241m.\u001b[39mwrite(\u001b[43mmodel_json\u001b[49m)\n\u001b[0;32m    110\u001b[0m \u001b[38;5;66;03m# Plot training and validation loss (log scale)\u001b[39;00m\n\u001b[0;32m    111\u001b[0m loss \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model_json' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.layers import Reshape, BatchNormalization, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import stats\n",
    "from ncps.tf import LTC\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Function to scale input data\n",
    "def scaled_in(matrix_spec):\n",
    "    \"Global scaling applied to noisy voice spectrograms (scale between -1 and 1)\"\n",
    "    matrix_spec = (matrix_spec + 46) / 50\n",
    "    return matrix_spec\n",
    "\n",
    "# Function to scale output data\n",
    "def scaled_ou(matrix_spec):\n",
    "    \"Global scaling applied to noise models spectrograms (scale between -1 and 1)\"\n",
    "    matrix_spec = (matrix_spec - 6) / 82\n",
    "    return matrix_spec\n",
    "\n",
    "# Load data\n",
    "path_save_spectrogram = '/content/drive/MyDrive/npy/'  # Specify the path to the spectrogram directory\n",
    "X_in = np.load(os.path.join(path_save_spectrogram, 'noisy_voice_amp_db.npy'))\n",
    "X_ou = np.load(os.path.join(path_save_spectrogram, 'voice_amp_db.npy'))\n",
    "\n",
    "# Model of noise to predict\n",
    "X_ou = X_in - X_ou\n",
    "\n",
    "# Check distribution\n",
    "print(stats.describe(X_in.reshape(-1, 1)))\n",
    "print(stats.describe(X_ou.reshape(-1, 1)))\n",
    "\n",
    "# Scale input and output data\n",
    "X_in = scaled_in(X_in)\n",
    "X_ou = scaled_ou(X_ou)\n",
    "\n",
    "# Check shape of spectrograms\n",
    "print(X_in.shape)\n",
    "print(X_ou.shape)\n",
    "# Check new distribution\n",
    "print(stats.describe(X_in.reshape(-1, 1)))\n",
    "print(stats.describe(X_ou.reshape(-1, 1)))\n",
    "\n",
    "# Reshape for training\n",
    "X_in = X_in[:, :, :]\n",
    "X_in = X_in.reshape(X_in.shape[0], X_in.shape[1], X_in.shape[2], 1)\n",
    "X_ou = X_ou[:, :, :]\n",
    "X_ou = X_ou.reshape(X_ou.shape[0], X_ou.shape[1], X_ou.shape[2], 1)\n",
    "\n",
    "# Split data into train and validation sets\n",
    "x_train, x_val, y_train, y_val = train_test_split(X_in, X_ou, test_size=0.10, random_state=42)\n",
    "\n",
    "# Load the saved UNet model\n",
    "unet_model = load_model('model_ResNet.keras')\n",
    "\n",
    "# Define RNN model\n",
    "ncp = LTC(32, 16)\n",
    "rnn_model = tf.keras.Sequential()\n",
    "rnn_model.add(Reshape((-1, 1)))  # Reshape to add a time dimension\n",
    "rnn_model.add(ncp)\n",
    "rnn_model.add(BatchNormalization())\n",
    "rnn_model.add(Dense(11, activation='softmax'))\n",
    "\n",
    "# Define the combined model\n",
    "combined_output = rnn_model(unet_model.output)\n",
    "combined_model = Model(inputs=unet_model.input, outputs=combined_output)\n",
    "\n",
    "# Compile the combined model\n",
    "combined_model.compile(optimizer='Adam',\n",
    "                       loss=tf.keras.losses.MeanSquaredError(),\n",
    "                       metrics=['mae'])\n",
    "\n",
    "# Define filepath for saving the best model\n",
    "model_checkpoint_path = 'best_model_combined.keras'\n",
    "\n",
    "# Define the ModelCheckpoint callback\n",
    "checkpoint = ModelCheckpoint(model_checkpoint_path,\n",
    "                             verbose=1,\n",
    "                             monitor='val_loss',\n",
    "                             save_best_only=True,\n",
    "                             mode='auto')\n",
    "\n",
    "# Train the combined model\n",
    "history = combined_model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=20, batch_size=10, callbacks=[checkpoint])\n",
    "\n",
    "# Save model architecture to JSON file\n",
    "model_json = combined_model.to_json()\n",
    "with open('model_combined.json', 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# Save model weights\n",
    "combined_model.save_weights('model_combined_weights.keras')\n",
    "\n",
    "# Plot training and validation loss (log scale)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, label='Training loss')\n",
    "plt.plot(epochs, val_loss, label='Validation loss')\n",
    "plt.yscale('log')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5b5f66-36ac-4663-9be7-8d6e23e849c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
