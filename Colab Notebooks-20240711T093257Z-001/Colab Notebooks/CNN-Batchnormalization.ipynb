{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPboHBMhejAtbMtUbUTLWvj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":106},"id":"EFQYZ_-6Z-hD","executionInfo":{"status":"error","timestamp":1716294768460,"user_tz":-720,"elapsed":351,"user":{"displayName":"Raveesh Malhotra","userId":"14937782039168808596"}},"outputId":"97ae0447-4174-44e2-8828-43ccb076b05d"},"outputs":[{"output_type":"error","ename":"IndentationError","evalue":"unexpected indent (<ipython-input-2-4ba33f87097d>, line 23)","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-4ba33f87097d>\"\u001b[0;36m, line \u001b[0;32m23\u001b[0m\n\u001b[0;31m    model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape))\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"]}],"source":["import os\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras import layers, models\n","from tensorflow.keras.layers import BatchNormalization\n","from sklearn.model_selection import train_test_split\n","from scipy import stats\n","\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import mean_squared_error\n","#from ncps.wirings import AutoNCP\n","#from ncps.tf import LTC\n","import tensorflow as tf\n","from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Reshape\n","\n","\n","def create_cnn_model(input_shape):\n","\n","   model = Sequential()\n","    # Convolutional layers\n","    model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape))\n","    model.add(BatchNormalization())  # Add batch normalization\n","    model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n","    model.add(BatchNormalization())  # Add batch normalization\n","    model.add(MaxPooling2D((2, 2)))\n","\n","    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n","    model.add(BatchNormalization())  # Add batch normalization\n","    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n","    model.add(BatchNormalization())  # Add batch normalization\n","    model.add(MaxPooling2D((2, 2)))\n","\n","    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n","    model.add(BatchNormalization())  # Add batch normalization\n","    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n","    model.add(BatchNormalization())  # Add batch normalization\n","    model.add(MaxPooling2D((2, 2)))\n","\n","    # Flatten layer\n","    model.add(Flatten())\n","\n","    # Dense layers\n","    model.add(Dense(128, activation='relu'))\n","    model.add(Dense(64, activation='relu'))\n","\n","    # Output layer\n","    model.add(Dense(128 * 128 * 1, activation='sigmoid'))  # Adjust the output shape to match the label shape\n","\n","    # Reshape output to match label shape\n","    model.add(Reshape((128, 128, 1)))\n","\n","    return model\n","# Model Definition Function\n","def create_lstm_model():\n","#height, width, channels = (78, 200, 3)\n","\n","   # ncp = LTC(AutoNCP(32, output_size=8), return_sequences=True)\n","    model = models.Sequential([\n","        layers.LSTM(64, return_sequences=True, input_shape=(128, 128)),  # LSTM layer with 64 units\n","        #BatchNormalization(),\n","        layers.LSTM(64, return_sequences=True),  # Second LSTM layer with 64 units\n","         BatchNormalization(),\n","        tf.keras.layers.TimeDistributed(tf.keras.layers.Activation(\"linear\")),\n","        #layers.LayerNormalization(),\n","        layers.Dense(128),\n","       # BatchNormalization()\n","    ])\n","    return model"]},{"cell_type":"code","source":["\n","def plot_accuracy(history):\n","    plt.figure(figsize=(10, 4))\n","\n","    # Plot training & validation accuracy values\n","    plt.plot(history.history['mae'])\n","    plt.plot(history.history['val_mae'])\n","    plt.title('Model Accuracy')\n","    plt.ylabel('Accuracy')\n","    plt.xlabel('Epoch')\n","    plt.legend(['Train', 'Validation'], loc='upper left')\n","    plt.show()\n","\n","# Function to plot predicted vs target spectrograms\n","def plot_spectrograms(y_val, y_pred):\n","    num_samples_to_visualize = 3\n","    sample_indices = np.random.choice(y_val.shape[0], num_samples_to_visualize, replace=False)\n","\n","    for idx in sample_indices:\n","        plt.figure(figsize=(12, 6))\n","\n","        # Display target spectrogram\n","        plt.subplot(1, 2, 1)\n","        plt.imshow(y_val[idx], cmap='viridis', origin='lower', aspect='auto')\n","        plt.colorbar()\n","        plt.title(f\"Target Spectrogram - Sample {idx}\")\n","\n","        # Display predicted spectrogram\n","        plt.subplot(1, 2, 2)\n","        plt.imshow(y_pred[idx], cmap='viridis', origin='lower', aspect='auto')\n","        plt.colorbar()\n","        plt.title(f\"Predicted Spectrogram - Sample {idx}\")\n","\n","        plt.tight_layout()\n","        plt.show()\n"],"metadata":{"id":"Orip68cQaJja"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Scaling functions\n","def scaled_in(matrix_spec):\n","    return (matrix_spec + 46) / 50\n","\n","def scaled_ou(matrix_spec):\n","    return (matrix_spec - 6) / 82\n","\n","# Data Preparation Function\n","def prepare_data(path_save_spectrogram):\n","    X_in = np.load(os.path.join(path_save_spectrogram, 'noisy_voice_amp_db.npy'))\n","    X_ou = np.load(os.path.join(path_save_spectrogram, 'voice_amp_db.npy'))\n","    X_ou = X_in - X_ou\n","    X_in = scaled_in(X_in)\n","    X_ou = scaled_ou(X_ou)\n","\n","    # Split into training and validation\n","    x_train, x_val, y_train, y_val = train_test_split(X_in, X_ou, test_size=0.10, random_state=42)\n","\n","    # Reshape for LSTMs (128 timesteps, 128 features)\n","    x_train_reshaped = x_train.reshape((x_train.shape[0], 128, 128))\n","    x_val_reshaped = x_val.reshape((x_val.shape[0], 128, 128))\n","    y_train_reshaped = y_train.reshape((y_train.shape[0], 128, 128))\n","    y_val_reshaped = y_val.reshape((y_val.shape[0], 128, 128))\n","\n","    return x_train_reshaped, x_val_reshaped, y_train_reshaped, y_val_reshaped\n","\n","\n","\n","# Training and Evaluation Function\n","def train_and_evaluate_model(model, x_train, x_val, y_train, y_val):\n","    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n","    initial_learning_rate=0.01,\n","    decay_steps=563,\n","    decay_rate=0.9,\n","    staircase=True)\n","\n","    print('x_train',x_train.shape)\n","    print('x_val',x_val.shape)\n","    print('y_train',y_train.shape)\n","    print('y_val',y_val.shape)\n","\n","    # Compile the model\n","    model.compile(\n","        optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n","        loss='mse',\n","        metrics=['mae']\n","    )\n","\n","    # ModelCheckpoint to save the best model\n","    model_checkpoint_path = 'best_model_lstm.keras'\n","    checkpoint = ModelCheckpoint(\n","        model_checkpoint_path,\n","        verbose=1,\n","        monitor='val_loss',\n","        save_best_only=True,\n","        mode='auto'\n","    )\n","\n","    print(\"Shape of y_val:\", y_val.shape)\n","   # print(\"Shape of y_pred:\", y_pred.shape)\n","    history = model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=35, batch_size=20, verbose=1)\n","\n","    y_pred = model.predict(x_val)\n","\n","    # Reshape target and prediction for MSE calculation\n","    y_val_flat = y_val.reshape(y_val.shape[0], -1)\n","    y_pred_flat = y_pred.reshape(y_pred.shape[0], -1)\n","    # Compute MSE\n","    mse = mean_squared_error(y_val_flat, y_pred_flat)\n","    print(f\"Mean Squared Error (MSE): {mse}\")\n","\n","    # Compute SNR\n","    def compute_snr(target, prediction):\n","        noise = target - prediction\n","        snr = 10 * np.log10(np.mean(target**2) / np.mean(noise**2))\n","        return snr\n","\n","    snr = compute_snr(y_val_flat, y_pred_flat)\n","    print(f\"Signal-to-Noise Ratio (SNR): {snr} dB\")\n","\n","\n","    # Plot training and validation loss\n","    loss = history.history['loss']\n","    val_loss = history.history['val_loss']\n","    epochs = range(1, len(loss) + 1)\n","\n","    plt.plot(epochs, loss, label='Training loss')\n","    plt.plot(epochs, val_loss, label='Validation loss')\n","    plt.title('Training and validation loss')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.show()\n","\n","    plot_accuracy(history)\n","\n","    # Plot predicted vs target spectrograms\n","    y_pred = model.predict(x_val)\n","    plot_spectrograms(y_val, y_pred)\n","\n","\n","    return history\n","\n","# Main Workflow\n","def main():\n","    # Data Preparation\n","    path_save_spectrogram = '/content/drive/MyDrive/npy/New1000/'\n","    x_train_reshaped, x_val_reshaped, y_train_reshaped, y_val_reshaped = prepare_data(path_save_spectrogram)\n","    input_shape = (128, 128, 1)\n","    # Create the model\n","    lstm_model = create_cnn_model(input_shape)\n","    #lstm_model = create_lstm_model()\n","\n","    # Train and evaluate the model\n","    train_and_evaluate_model(lstm_model, x_train_reshaped, x_val_reshaped, y_train_reshaped, y_val_reshaped)\n","\n","    # Save the model architecture and weights\n","    model_json = lstm_model.to_json()\n","    with open('model_lstm.json', 'w') as json_file:\n","        json_file.write(model_json)\n","\n","    lstm_model.save_weights('model_lstm_weights.keras')\n","\n","# Run the main function\n","if __name__ == \"__main__\":\n","    main()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":339},"id":"MB908WSIaNg_","executionInfo":{"status":"error","timestamp":1716294762637,"user_tz":-720,"elapsed":28168,"user":{"displayName":"Raveesh Malhotra","userId":"14937782039168808596"}},"outputId":"aa58ea10-39c7-44b1-a905-dbfba23dfcb5"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]},{"output_type":"error","ename":"NameError","evalue":"name 'np' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-0fa267ba2a06>\u001b[0m in \u001b[0;36m<cell line: 128>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;31m# Run the main function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-1-0fa267ba2a06>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;31m# Data Preparation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0mpath_save_spectrogram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/npy/New1000/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m     \u001b[0mx_train_reshaped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_val_reshaped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_reshaped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_reshaped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_save_spectrogram\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m     \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;31m# Create the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-1-0fa267ba2a06>\u001b[0m in \u001b[0;36mprepare_data\u001b[0;34m(path_save_spectrogram)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Data Preparation Function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprepare_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_save_spectrogram\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mX_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_save_spectrogram\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'noisy_voice_amp_db.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mX_ou\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_save_spectrogram\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'voice_amp_db.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mX_ou\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_in\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mX_ou\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"]}]}]}