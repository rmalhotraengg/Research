{"cells":[{"cell_type":"code","source":["pip install ncps"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5T8wcq2JDBJ_","executionInfo":{"status":"ok","timestamp":1712652577641,"user_tz":-720,"elapsed":12710,"user":{"displayName":"Raveesh Malhotra","userId":"14937782039168808596"}},"outputId":"6a3e896b-e9a1-442a-e693-b26bff6b8b4b"},"id":"5T8wcq2JDBJ_","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ncps\n","  Downloading ncps-0.0.7-py3-none-any.whl (44 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m795.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ncps) (0.18.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ncps) (24.0)\n","Installing collected packages: ncps\n","Successfully installed ncps-0.0.7\n"]}]},{"cell_type":"code","execution_count":11,"id":"6472cc7b-e683-41de-905b-aba016cc15cc","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"6472cc7b-e683-41de-905b-aba016cc15cc","executionInfo":{"status":"error","timestamp":1712654468371,"user_tz":-720,"elapsed":475198,"user":{"displayName":"Raveesh Malhotra","userId":"14937782039168808596"}},"outputId":"44d33d21-bf54-4d60-b90c-5ee1a2e7b79f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Mounting Google Drive... Done.\n","Defining scaled_in function... Done.\n","Defining scaled_ou function... Done.\n","Loading data...\n","Data loaded successfully.\n","Checking distribution of input data...\n","DescribeResult(nobs=8192000, minmax=(array([-80.]), array([0.])), mean=array([-36.32202353]), variance=array([173.18573026]), skewness=array([-0.62897657]), kurtosis=array([1.16821915]))\n","DescribeResult(nobs=8192000, minmax=(array([-63.09787973]), array([77.94489739])), mean=array([0.36134002]), variance=array([96.05843834]), skewness=array([0.62643615]), kurtosis=array([2.30614789]))\n","Distribution check completed.\n","Scaling input and output data...\n","Data scaled successfully.\n","Checking shape of spectrograms...\n","Input shape: (500, 128, 128)\n","Output shape: (500, 128, 128)\n","Shape check completed.\n","Reshaping data for training...\n","Data reshaped successfully.\n","Splitting data into train and validation sets...\n","Data split completed.\n","Loading saved UNet model...\n","UNet model loaded successfully.\n","Defining RNN model...\n","RNN model defined successfully.\n","Defining the combined model...\n","Combined model defined successfully.\n","Compiling the combined model...\n","Combined model compiled successfully.\n","Training the combined model...\n","Epoch 1/20\n"]},{"output_type":"error","ename":"ValueError","evalue":"in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1151, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1209, in compute_loss\n        return self.compiled_loss(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 143, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 270, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 1706, in mean_squared_error\n        return backend.mean(tf.math.squared_difference(y_pred, y_true), axis=-1)\n\n    ValueError: Dimensions must be equal, but are 10 and 128 for '{{node mean_squared_error/SquaredDifference}} = SquaredDifference[T=DT_FLOAT](model/sequential/dense/Softmax, IteratorGetNext:1)' with input shapes: [10,11], [10,128,128,1].\n","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-3440cbf5b303>\u001b[0m in \u001b[0;36m<cell line: 115>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;31m# Train the combined model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training the combined model...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombined_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training completed.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1151, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1209, in compute_loss\n        return self.compiled_loss(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 143, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 270, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 1706, in mean_squared_error\n        return backend.mean(tf.math.squared_difference(y_pred, y_true), axis=-1)\n\n    ValueError: Dimensions must be equal, but are 10 and 128 for '{{node mean_squared_error/SquaredDifference}} = SquaredDifference[T=DT_FLOAT](model/sequential/dense/Softmax, IteratorGetNext:1)' with input shapes: [10,11], [10,128,128,1].\n"]}],"source":["import os\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import load_model, Model\n","from tensorflow.keras.layers import Reshape, BatchNormalization, Dense\n","from sklearn.model_selection import train_test_split\n","from scipy import stats\n","from ncps.tf import LTC\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","print(\"Mounting Google Drive... Done.\")\n","\n","# Function to scale input data\n","def scaled_in(matrix_spec):\n","    \"Global scaling applied to noisy voice spectrograms (scale between -1 and 1)\"\n","    matrix_spec = (matrix_spec + 46) / 50\n","    return matrix_spec\n","\n","print(\"Defining scaled_in function... Done.\")\n","\n","# Function to scale output data\n","def scaled_ou(matrix_spec):\n","    \"Global scaling applied to noise models spectrograms (scale between -1 and 1)\"\n","    matrix_spec = (matrix_spec - 6) / 82\n","    return matrix_spec\n","\n","print(\"Defining scaled_ou function... Done.\")\n","\n","# Load data\n","path_save_spectrogram = '/content/drive/MyDrive/npy/'  # Specify the path to the spectrogram directory\n","\n","print(\"Loading data...\")\n","X_in = np.load(os.path.join(path_save_spectrogram, 'noisy_voice_amp_db.npy'))\n","X_ou = np.load(os.path.join(path_save_spectrogram, 'voice_amp_db.npy'))\n","print(\"Data loaded successfully.\")\n","\n","# Model of noise to predict\n","X_ou = X_in - X_ou\n","\n","# Check distribution\n","print(\"Checking distribution of input data...\")\n","print(stats.describe(X_in.reshape(-1, 1)))\n","print(stats.describe(X_ou.reshape(-1, 1)))\n","print(\"Distribution check completed.\")\n","\n","# Scale input and output data\n","print(\"Scaling input and output data...\")\n","X_in = scaled_in(X_in)\n","X_ou = scaled_ou(X_ou)\n","print(\"Data scaled successfully.\")\n","\n","# Check shape of spectrograms\n","print(\"Checking shape of spectrograms...\")\n","print(\"Input shape:\", X_in.shape)\n","print(\"Output shape:\", X_ou.shape)\n","print(\"Shape check completed.\")\n","\n","# Reshape for training\n","print(\"Reshaping data for training...\")\n","X_in = X_in[:, :, :]\n","X_in = X_in.reshape(X_in.shape[0], X_in.shape[1], X_in.shape[2], 1)\n","X_ou = X_ou[:, :, :]\n","X_ou = X_ou.reshape(X_ou.shape[0], X_ou.shape[1], X_ou.shape[2], 1)\n","print(\"Data reshaped successfully.\")\n","\n","# Split data into train and validation sets\n","print(\"Splitting data into train and validation sets...\")\n","x_train, x_val, y_train, y_val = train_test_split(X_in, X_ou, test_size=0.10, random_state=42)\n","print(\"Data split completed.\")\n","\n","# Load the saved UNet model\n","print(\"Loading saved UNet model...\")\n","unet_model = load_model(os.path.join(path_save_spectrogram, 'weights/model_ResNet.keras'))\n","print(\"UNet model loaded successfully.\")\n","\n","# Define RNN model\n","print(\"Defining RNN model...\")\n","ncp = LTC(32, 16)\n","rnn_model = tf.keras.Sequential()\n","rnn_model.add(Reshape((-1, 1)))  # Reshape to add a time dimension\n","rnn_model.add(ncp)\n","rnn_model.add(BatchNormalization())\n","rnn_model.add(Dense(11, activation='softmax'))\n","print(\"RNN model defined successfully.\")\n","\n","# Define the combined model\n","print(\"Defining the combined model...\")\n","combined_output = rnn_model(unet_model.output)\n","combined_model = Model(inputs=unet_model.input, outputs=combined_output)\n","print(\"Combined model defined successfully.\")\n","\n","# Compile the combined model\n","print(\"Compiling the combined model...\")\n","combined_model.compile(optimizer='Adam',\n","                       loss=tf.keras.losses.MeanSquaredError(),\n","                       metrics=['mae'])\n","print(\"Combined model compiled successfully.\")\n","\n","# Define filepath for saving the best model\n","model_checkpoint_path = 'best_model_combined.keras'\n","\n","# Define the ModelCheckpoint callback\n","checkpoint = ModelCheckpoint(model_checkpoint_path,\n","                             verbose=1,\n","                             monitor='val_loss',\n","                             save_best_only=True,\n","                             mode='auto')\n","\n","# Train the combined model\n","print(\"Training the combined model...\")\n","history = combined_model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=20, batch_size=10, verbose=1, callbacks=[checkpoint])\n","print(\"Training completed.\")\n","\n","# Save model architecture to JSON file\n","print(\"Saving model architecture to JSON file...\")\n","model_json = combined_model.to_json()\n","with open('model_combined.json', 'w') as json_file:\n","    json_file.write(model_json)\n","print(\"Model architecture saved successfully.\")\n","\n","# Save model weights\n","print(\"Saving model weights...\")\n","combined_model.save_weights('model_combined_weights.keras')\n","print(\"Model weights saved successfully.\")\n","\n","# Plot training and validation loss (log scale)\n","import matplotlib.pyplot as plt\n","\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","epochs = range(1, len(loss) + 1)\n","\n","plt.plot(epochs, loss, label='Training loss')\n","plt.plot(epochs, val_loss, label='Validation loss')\n","plt.yscale('log')\n","plt.title('Training and validation loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.show()\n","\n","# Print epoch information and other variables\n","print(\"Epochs:\", epochs)\n","print(\"Training Loss:\", loss)\n","print(\"Validation Loss:\", val_loss)\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}