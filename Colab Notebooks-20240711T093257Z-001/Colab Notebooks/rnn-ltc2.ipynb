{"cells":[{"cell_type":"code","execution_count":2,"id":"JHQrRJsZ_k8r","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8182,"status":"ok","timestamp":1712731232852,"user":{"displayName":"Raveesh Malhotra","userId":"14937782039168808596"},"user_tz":-720},"id":"JHQrRJsZ_k8r","outputId":"4efa6590-b6f0-4bc7-9400-0a3011ad2287"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting ncps\n","  Downloading ncps-0.0.7-py3-none-any.whl (44 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m799.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ncps) (0.18.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ncps) (24.0)\n","Installing collected packages: ncps\n","Successfully installed ncps-0.0.7\n"]}],"source":["pip install ncps"]},{"cell_type":"code","execution_count":3,"id":"c92023b2-5dd2-408a-8106-97845b6c1176","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":862},"executionInfo":{"elapsed":147305,"status":"error","timestamp":1712731381764,"user":{"displayName":"Raveesh Malhotra","userId":"14937782039168808596"},"user_tz":-720},"id":"c92023b2-5dd2-408a-8106-97845b6c1176"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Mounting Google Drive... Done.\n","Defining scaled_in function... Done.\n","Defining scaled_ou function... Done.\n","Loading data...\n","Data loaded successfully.\n","Checking distribution of input data...\n","DescribeResult(nobs=8192000, minmax=(array([-80.]), array([0.])), mean=array([-36.32202353]), variance=array([173.18573026]), skewness=array([-0.62897657]), kurtosis=array([1.16821915]))\n","DescribeResult(nobs=8192000, minmax=(array([-63.09787973]), array([77.94489739])), mean=array([0.36134002]), variance=array([96.05843834]), skewness=array([0.62643615]), kurtosis=array([2.30614789]))\n","Distribution check completed.\n","Scaling input and output data...\n","Data scaled successfully.\n","Checking shape of spectrograms...\n","Input shape: (500, 128, 128)\n","Output shape: (500, 128, 128)\n","Shape check completed.\n","Data reshaped successfully.\n","(450, 128, 128) (50, 128, 128) (450, 128, 128) (50, 128, 128)\n","(450, 16384) (50, 16384)\n","Data split completed.\n","Defining RNN model...\n","RNN model defined successfully.\n","Compiling the RNN model...\n","RNN model compiled successfully.\n","Training the RNN model...\n","Epoch 1/20\n","90/90 [==============================] - ETA: 0s - loss: 0.0191 - mae: 0.1124 \n","Epoch 1: val_loss improved from inf to 0.01875, saving model to best_model_ltc.keras\n","90/90 [==============================] - 3328s 37s/step - loss: 0.0191 - mae: 0.1124 - val_loss: 0.0187 - val_mae: 0.1109\n","Epoch 2/20\n","90/90 [==============================] - ETA: 0s - loss: 0.0191 - mae: 0.1124 \n","Epoch 2: val_loss did not improve from 0.01875\n","90/90 [==============================] - 3297s 37s/step - loss: 0.0191 - mae: 0.1124 - val_loss: 0.0187 - val_mae: 0.1109\n","Epoch 3/20\n","90/90 [==============================] - ETA: 0s - loss: 0.0191 - mae: 0.1124 \n","Epoch 3: val_loss did not improve from 0.01875\n","90/90 [==============================] - 3292s 37s/step - loss: 0.0191 - mae: 0.1124 - val_loss: 0.0187 - val_mae: 0.1109\n","Epoch 4/20\n","90/90 [==============================] - ETA: 0s - loss: 0.0191 - mae: 0.1124 \n","Epoch 4: val_loss did not improve from 0.01875\n","90/90 [==============================] - 3279s 36s/step - loss: 0.0191 - mae: 0.1124 - val_loss: 0.0187 - val_mae: 0.1109\n","Epoch 5/20\n","90/90 [==============================] - ETA: 0s - loss: 0.0191 - mae: 0.1124 \n","Epoch 5: val_loss did not improve from 0.01875\n","90/90 [==============================] - 3247s 36s/step - loss: 0.0191 - mae: 0.1124 - val_loss: 0.0187 - val_mae: 0.1109\n","Epoch 6/20\n","90/90 [==============================] - ETA: 0s - loss: 0.0191 - mae: 0.1124 \n","Epoch 6: val_loss did not improve from 0.01875\n","90/90 [==============================] - 3286s 37s/step - loss: 0.0191 - mae: 0.1124 - val_loss: 0.0187 - val_mae: 0.1109\n","Epoch 7/20\n"," 1/90 [..............................] - ETA: 52:28 - loss: 0.0101 - mae: 0.0859"]}],"source":["import os\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.layers import Reshape, BatchNormalization, Dense,LSTM, Flatten\n","from sklearn.model_selection import train_test_split\n","from scipy import stats\n","from ncps.tf import LTC\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","print(\"Mounting Google Drive... Done.\")\n","\n","# Function to scale input data\n","def scaled_in(matrix_spec):\n","    \"Global scaling applied to noisy voice spectrograms (scale between -1 and 1)\"\n","    matrix_spec = (matrix_spec + 46) / 50\n","    return matrix_spec\n","\n","print(\"Defining scaled_in function... Done.\")\n","\n","# Function to scale output data\n","def scaled_ou(matrix_spec):\n","    \"Global scaling applied to noise models spectrograms (scale between -1 and 1)\"\n","    matrix_spec = (matrix_spec - 6) / 82\n","    return matrix_spec\n","\n","print(\"Defining scaled_ou function... Done.\")\n","\n","# Load data\n","path_save_spectrogram = '/content/drive/MyDrive/npy/'  # Specify the path to the spectrogram directory\n","\n","print(\"Loading data...\")\n","X_in = np.load(os.path.join(path_save_spectrogram, 'noisy_voice_amp_db.npy'))\n","X_ou = np.load(os.path.join(path_save_spectrogram, 'voice_amp_db.npy'))\n","print(\"Data loaded successfully.\")\n","\n","# Model of noise to predict\n","X_ou = X_in - X_ou\n","\n","# Check distribution\n","print(\"Checking distribution of input data...\")\n","print(stats.describe(X_in.reshape(-1, 1)))\n","print(stats.describe(X_ou.reshape(-1, 1)))\n","print(\"Distribution check completed.\")\n","\n","# Scale input and output data\n","print(\"Scaling input and output data...\")\n","X_in = scaled_in(X_in)\n","X_ou = scaled_ou(X_ou)\n","print(\"Data scaled successfully.\")\n","\n","# Check shape of spectrograms\n","print(\"Checking shape of spectrograms...\")\n","print(\"Input shape:\", X_in.shape)\n","print(\"Output shape:\", X_ou.shape)\n","print(\"Shape check completed.\")\n","\n","\n","print(\"Data reshaped successfully.\")\n","import numpy as np\n","import tensorflow as tf\n","# Split data into train and validation sets\n","x_train, x_val, y_train, y_val = train_test_split(X_in, X_ou, test_size=0.10, random_state=42)\n","y_train_reshaped =  np.reshape(y_train, (450, -1))\n","y_val_reshaped = np.reshape(y_val, (50, -1))\n","\n","print(x_train.shape, x_val.shape, y_train.shape, y_val.shape)\n","print(y_train_reshaped.shape, y_val_reshaped.shape)\n","print(\"Data split completed.\")\n","\n","# Load the saved UNet model\n","# No UNet model in this case, since we're only using RNNs\n","\n","# Define RNN model\n","print(\"Defining RNN model...\")\n","ncp = LTC(32, 16)\n","rnn_model = tf.keras.Sequential([\n","    Reshape((-1, 1)),              # Reshape to add a time dimension\n","    ncp,\n","    BatchNormalization(),\n","    Dense(128 * 128 * 1, activation='softmax')\n","    #Reshape((128, -1)),  # Reshape output of NCP layer to match LSTM input shape\n","    #LSTM(128, return_sequences=True),# Flatten the output\n","    #LSTM(128, return_sequences=True),  # LSTM layer with 128 units\n","    #Conv2D(1, kernel_size=(1, 1), activation='softmax')\n","    #Reshape((-1, 128, 1)),  # Reshape output of Dense layer to match (batch_size, 128, 1)\n","    #tf.keras.layers.ZeroPadding2D(((0,0), (0,127))),        # Reshape to match desired output shape\n","])\n"," # Reshape to match the shape of the true output\n","print(\"RNN model defined successfully.\")\n","\n","#print(\"Shape after NCP layer:\", rnn_model.predict(x_train).shape)\n","\n","\n","# Compile the RNN model\n","print(\"Compiling the RNN model...\")\n","rnn_model.compile(optimizer='Adam',\n","                  loss='mean_squared_error',  # Use mean squared error loss\n","                  metrics=['mae'])\n","print(\"RNN model compiled successfully.\")\n","\n","# Define filepath for saving the best model\n","model_checkpoint_path = 'best_model_ltc.keras'\n","\n","# Define the ModelCheckpoint callback\n","checkpoint = ModelCheckpoint(model_checkpoint_path,\n","                             verbose=1,\n","                             monitor='val_loss',\n","                             save_best_only=True,\n","                             mode='auto')\n","\n","# Train the RNN model\n","print(\"Training the RNN model...\")\n","history = rnn_model.fit(x_train, y_train_reshaped, validation_data=(x_val, y_val_reshaped), epochs=20,\n","                        batch_size=5, verbose=1, callbacks=[checkpoint])\n","print(\"Training completed.\")\n","\n","# Save model architecture to JSON file\n","print(\"Saving model architecture to JSON file...\")\n","model_json = rnn_model.to_json()\n","with open('model_ltc.json', 'w') as json_file:\n","    json_file.write(model_json)\n","print(\"Model architecture saved successfully.\")\n","\n","# Save model weights\n","print(\"Saving model weights...\")\n","rnn_model.save_weights('model_rnn_weights.keras')\n","print(\"Model weights saved successfully.\")\n","\n","# Plot training and validation loss\n","import matplotlib.pyplot as plt\n","\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","epochs = range(1, len(loss) + 1)\n","\n","plt.plot(epochs, loss, label='Training loss')\n","plt.plot(epochs, val_loss, label='Validation loss')\n","plt.title('Training and validation loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.show()\n","\n","# Print epoch information and other variables\n","print(\"Epochs:\", epochs)\n","print(\"Training Loss:\", loss)\n","print(\"Validation Loss:\", val_loss)\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":5}